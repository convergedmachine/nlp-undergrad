{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll explore named entity recognition through the lens of toponym resolution, using NER to extract a list of geopolitical place names in a text, and then plotting those locations on a map (using the Folium mapping library -- see [here](https://blog.prototypr.io/interactive-maps-with-python-part-1-aa1563dbe5a9) for a Folium tutorial).\n",
    "\n",
    "You'll need to install the following:\n",
    "```sh\n",
    "pip install folium==0.8.3\n",
    "pip install wikipedia==1.4.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 2: Importing Libraries\n",
    "This cell imports all the necessary Python libraries for the project.\n",
    "* **folium**: Used to create interactive maps.\n",
    "* **wikipedia**: Used to fetch text content from Wikipedia articles.\n",
    "* **spacy**: A powerful library for Natural Language Processing (NLP), used here for Named Entity Recognition (NER).\n",
    "* **Counter**: A dictionary subclass from the `collections` module for counting hashable objects, perfect for tallying the frequency of locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the folium library for creating interactive maps.\n",
    "import folium\n",
    "# Import the wikipedia library to fetch content from Wikipedia articles.\n",
    "import wikipedia\n",
    "# Import the spacy library for natural language processing tasks.\n",
    "import spacy\n",
    "# From the collections module, import the Counter class to count entity occurrences.\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 3: Loading the spaCy Model\n",
    "Here, we load a pre-trained English language model from spaCy. We disable the 'parser' component because we only need the Named Entity Recognizer (NER) for this task, which makes the process more efficient. A commented-out line provides an alternative model name (`en_core_web_sm`) which is a common fix if the default 'en' alias isn't set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the default English language model from spaCy.\n",
    "# We disable the 'parser' pipeline component to speed up processing as we only need NER.\n",
    "nlp = spacy.load('en', disable=['parser'])\n",
    "\n",
    "# This is a workaround in case loading 'en' fails. \n",
    "# It explicitly loads a specific small English model.\n",
    "# nlp = spacy.load('en_core_web_sm', disable=['parser'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 4: Georeferencing Strategy\n",
    "There are several good APIs for resolving place names to their latitude/longitude (such as [Nominatim](https://wiki.openstreetmap.org/wiki/Nominatim) from OpenStreetMap and Google's [Geocoding API](https://developers.google.com/maps/documentation/geocoding/)).  Those are typically rate-limited or not free, so for this notebook let's use a simple georeferencer using data from [GeoNames](http://download.geonames.org/export/dump/) -- we'll assign each mention of a geopolitical entity placename to the city with the same name; in cases of ambiguity (e.g., Cambridge, MA vs. Cambridge UK), we'll select the city with the greatest population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 5: Function to Read GeoNames Data\n",
    "This cell defines the `read_geonames` function, which reads and parses data from two text files: one for cities and one for countries. It extracts relevant information like name, population, latitude, and longitude for cities, and just the names for countries. This data will be our knowledge base for mapping place names to coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read and parse city and country data from files.\n",
    "def read_geonames(city_filename, country_filename):\n",
    "    # Initialize an empty list to store city data.\n",
    "    cities=[]\n",
    "    # Initialize an empty list to store country names.\n",
    "    countries=[]\n",
    "    \n",
    "    # Open the city data file.\n",
    "    with open(city_filename) as file:\n",
    "        # Loop through each line in the file, with its index.\n",
    "        for idx,line in enumerate(file):\n",
    "            # Split the tab-separated line into columns.\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            # Get the city name from the second column and convert to lowercase.\n",
    "            name=cols[1].lower()\n",
    "            # Get the latitude from the fifth column and convert to a float.\n",
    "            lat=float(cols[4])\n",
    "            # Get the longitude from the sixth column and convert to a float.\n",
    "            long=float(cols[5])\n",
    "            # Get the population from the 15th column and convert to an integer.\n",
    "            population=int(cols[14])\n",
    " \n",
    "            # Append a tuple of the extracted city data to the cities list.\n",
    "            cities.append((name, population, lat, long))\n",
    "\n",
    "    # Open the country information file.\n",
    "    with open(country_filename) as file:\n",
    "        # Loop through each line in the file, with its index.\n",
    "        for idx,line in enumerate(file):\n",
    "            # Skip header lines that start with '#'.\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            # Split the tab-separated line into columns.\n",
    "            cols=line.rstrip().split(\"\\t\")    \n",
    "            # Get the country name from the fifth column and convert to lowercase.\n",
    "            name=cols[4].lower()\n",
    "            # Add the country name to the countries list.\n",
    "            countries.append(name)\n",
    "            \n",
    "    # Return the list of cities and a set of unique country names for faster lookups.\n",
    "    return cities, set(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 6: Executing the Data Loading\n",
    "This code calls the `read_geonames` function with the paths to our data files. It loads the city and country information into the `cities` and `countries` variables, making them available for the rest of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to read the GeoNames files and load the data into variables.\n",
    "# Note: The file paths \"../data/...\" assume the data is in a folder named 'data' one directory up.\n",
    "cities, countries=read_geonames(\"../data/cities500.txt\", \"../data/countryInfo.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 7: Function to Resolve Toponyms\n",
    "The `resolve_toponyms` function is the core of our location resolution logic. It takes the list of locations found in a text and tries to map them to geographic coordinates. To handle ambiguity (e.g., \"Paris,\" France vs. \"Paris,\" Texas), it simplifies the problem by always choosing the city with the largest population for a given name. It also filters out country names from the city list to avoid confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to map extracted place names to coordinates.\n",
    "def resolve_toponyms(locations, cities, countries, doc):\n",
    "    \"\"\" Resolve a counter of GPE entities to their latitude/longitude coordinates\n",
    "    Input: \n",
    "        - locations: counter mapping GPE entities to their count in a text\n",
    "        - cities: list of cities containing (placename, population, lat, long) tuples\n",
    "        - countries: set of country names\n",
    "        - doc: spacy-processed document containing all tokens, entities, etc.\n",
    "        \n",
    "    Output: dict mapping each GPE entity to (lat, long) tuple \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to store the final coordinates for entities found in the text.\n",
    "    coordinates={}\n",
    "    \n",
    "    # Initialize a temporary dictionary to hold the most populous city for each unique place name.\n",
    "    new_geo={}\n",
    "    \n",
    "    # Iterate through all cities from our GeoNames data.\n",
    "    for (placename, population, lat, long) in cities:\n",
    "        # Skip this entry if the city name is also a country name to avoid ambiguity.\n",
    "        if placename in countries:\n",
    "            continue\n",
    "            \n",
    "        # If we have already seen a city with this name...\n",
    "        if placename in new_geo:\n",
    "            # ...get its currently stored population.\n",
    "            _, cur_pop, _, _=new_geo[placename]\n",
    "            # If the new city's population is greater, replace the old entry.\n",
    "            if population > cur_pop:\n",
    "                new_geo[placename]=(placename, population, lat, long)\n",
    "        # If this is the first time we've seen this city name, add it.\n",
    "        else:\n",
    "            new_geo[placename]=(placename, population, lat, long)\n",
    "    \n",
    "    \n",
    "    # Now, iterate through the unique locations found in the input text.\n",
    "    for entity in locations:\n",
    "        # If the location from the text exists in our cleaned-up geo dictionary...\n",
    "        if entity in new_geo:\n",
    "            # ...add its latitude and longitude to our results.\n",
    "            coordinates[entity]=(new_geo[entity][2], new_geo[entity][3])\n",
    "    \n",
    "    # Return the dictionary mapping found entities to their coordinates.\n",
    "    return coordinates\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 8: Function to Map Toponyms\n",
    "The `map_toponyms` function ties everything together. It takes raw text, processes it with spaCy to find all geopolitical entities (GPEs), counts their occurrences, resolves them to coordinates using our `resolve_toponyms` function, and finally generates and returns an interactive Folium map. The map is centered on the most frequently mentioned location, and each location is marked with a circle whose radius corresponds to how often it was mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main function to process text and generate a map.\n",
    "def map_toponyms(text, cities, countries):\n",
    "    # Process the input text with our spaCy nlp object.\n",
    "    doc=nlp(text)\n",
    "    \n",
    "    # Create a Counter object to store the frequency of each location.\n",
    "    locations=Counter()\n",
    "    # Iterate through all named entities found by spaCy.\n",
    "    for entity in doc.ents:\n",
    "        # We are only interested in entities labeled as \"GPE\" (Geopolitical Entity).\n",
    "        if entity.label_ == \"GPE\":\n",
    "            # Increment the count for this location (converted to lowercase).\n",
    "            locations[entity.text.lower()]+=1\n",
    "\n",
    "\n",
    "    # Call our previously defined function to get coordinates for the found locations.\n",
    "    coordinates=resolve_toponyms(locations, cities, countries, doc)\n",
    "\n",
    "    # Initialize variables to find the most frequent entity to center the map on.\n",
    "    center=None\n",
    "    maxentity=None\n",
    "    maxcount=0\n",
    "    # Iterate through the locations that we successfully found coordinates for.\n",
    "    for entity in coordinates:\n",
    "        # Check if the current entity's count is the highest so far.\n",
    "        if locations[entity] > maxcount:\n",
    "            # If so, update the max count.\n",
    "            maxcount=locations[entity]\n",
    "            # Set the map's center to this entity's coordinates.\n",
    "            center=[coordinates[entity][0], coordinates[entity][1]]\n",
    "\n",
    "            # Keep track of the entity's name.\n",
    "            maxentity=entity\n",
    "            \n",
    "    # Create a Folium map object.\n",
    "    folium_map = folium.Map(location=center,       # Center the map on the most frequent location.\n",
    "                            zoom_start=3,          # Set an initial zoom level.\n",
    "                            tiles=\"CartoDB dark_matter\") # Use a dark-themed map style.\n",
    "\n",
    "    # Add markers for each location to the map.\n",
    "    for entity in coordinates:\n",
    "        # Set the radius of the circle marker based on the location's frequency.\n",
    "        radius=locations[entity]\n",
    "        # Create the circle marker with its location, radius, and a popup label.\n",
    "        marker = folium.CircleMarker(location=[coordinates[entity][0], coordinates[entity][1]], radius=radius, fill=True, popup=entity)\n",
    "        # Add the marker to the map.\n",
    "        marker.add_to(folium_map)\n",
    "    \n",
    "    # Return the completed map object.\n",
    "    return folium_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 9: Testing with Wikipedia Articles\n",
    "Let's test our method by pulling articles from Wikipedia and plotting the placenames mentioned in them.  Explore this -- try inputting other Wikipedia articles and visualizing the places.  Let us all know if you find an interesting one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 10: Fetching Wikipedia Content\n",
    "This cell uses the `wikipedia` library to download the full text content of three different articles. These will serve as our sample texts to test the mapping function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Wikipedia page object for \"University of California, Berkeley\".\n",
    "ucb = wikipedia.page(\"University of California, Berkeley\")\n",
    "# Get the Wikipedia page object for \"New York City\".\n",
    "nyc = wikipedia.page(\"New York City\")\n",
    "# Get the Wikipedia page object for \"World War II\".\n",
    "ww2 = wikipedia.page(\"World War II\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 11: Generating the Map for New York City\n",
    "Here, we call our main `map_toponyms` function, passing the content of the \"New York City\" Wikipedia article. This will perform all the steps—NER, coordinate resolution, and map creation—and store the final map object in the `folium_map` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a map for the content of the New York City Wikipedia page.\n",
    "folium_map=map_toponyms(nyc.content, cities, countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 12: Displaying the Map\n",
    "Simply referencing the `folium_map` object at the end of a cell in a Jupyter environment will cause it to be rendered as an interactive map in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the interactive map generated in the previous cell.\n",
    "folium_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 13: Testing with a Full Book\n",
    "Now let's try it with the full text of a book (Mark Twain's travelogue *Innocents Abroad*).  Running this through spacy will take a minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 14: Processing the Book Text\n",
    "This cell reads the entire text of Mark Twain's *Innocents Abroad* from a local file and then passes this large string to our `map_toponyms` function to generate a map of all the places mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text file containing the book.\n",
    "with open(\"../data/twain_innocents_abroad.txt\") as file:\n",
    "    # Read the entire content of the file into the 'data' variable.\n",
    "    data=file.read()\n",
    "# Call the mapping function with the book's full text.\n",
    "folium_map=map_toponyms(data, cities, countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 15: Displaying the Book Map\n",
    "As before, this cell displays the map created from the book's text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the interactive map for \"Innocents Abroad\".\n",
    "folium_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 16: Reflection on Errors and Improvements\n",
    "You can see the kind of errors that our homemade toponym resolution is making.  How would you go about improving it?  What kind of information do you have in a text to make it better? Try to adapt `resolve_toponyms` to improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 17: Your Turn to Code\n",
    "This empty cell is a space for you to experiment with and implement improvements to the `resolve_toponyms` function based on the challenges identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an empty cell for you to write your own improved function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loc",
   "language": "python",
   "name": "loc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
