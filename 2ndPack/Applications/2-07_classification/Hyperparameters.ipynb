{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores text classification, introducing a majority class baseline and analyzing the effect of hyperparameter choices on accuracy. The goal is to understand how different settings in feature extraction and model regularization impact performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys # Provides access to system-specific parameters and functions\n",
    "from collections import Counter # A dictionary subclass for counting hashable objects\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Converts text to a matrix of token counts\n",
    "from sklearn import preprocessing # Provides tools for data preprocessing, like label encoding\n",
    "from sklearn import linear_model # Contains linear models like Logistic Regression\n",
    "import pandas as pd # A library for data manipulation and analysis, used here for plotting\n",
    "import numpy as np # A fundamental package for scientific computing with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading\n",
    "\n",
    "First, we define a function to read our data. The data is expected to be in a Tab-Separated Values (`.tsv`) format, with each line containing a label and the corresponding text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read data from a file\n",
    "def read_data(filename):\n",
    "    # Initialize empty lists to store the text data (features) and labels\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    # Open the specified file with UTF-8 encoding to handle various characters\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        # Iterate over each line in the file\n",
    "        for line in file:\n",
    "            # Split the line by the tab character (\"\\t\") and remove any trailing whitespace\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            # The first column is the label\n",
    "            label=cols[0]\n",
    "            # The second column is the text\n",
    "            text=cols[1]\n",
    "            # The sample text data is already tokenized (words are separated by spaces).\n",
    "            # If your data is not tokenized, you would do it here.\n",
    "            \n",
    "            # Append the text to the feature list X\n",
    "            X.append(text)\n",
    "            # Append the label to the label list Y\n",
    "            Y.append(label)\n",
    "    # Return the lists of features (X) and labels (Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify the directory where the training, development, and test data files are located. You'll need to change this path to match the location on your own system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to the directory with your data.\n",
    "# The directory should contain train.tsv, dev.tsv, and test.tsv files.\n",
    "directory=\"../data/text_classification_sample_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function and path defined above, we now load the training and development (validation) datasets into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training data from 'train.tsv'\n",
    "trainX, trainY = read_data(\"%s/train.tsv\" % directory)\n",
    "# Read the development (validation) data from 'dev.tsv'\n",
    "devX, devY = read_data(\"%s/dev.tsv\" % directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Majority Class Baseline\n",
    "\n",
    "Baselines are crucial for understanding how well a model is performing. A simple yet effective baseline is the **majority class baseline**. This method predicts the most frequent label from the **training data** for every single example in the development set. If our sophisticated model can't beat this simple baseline, it's not very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the majority class baseline accuracy\n",
    "def majority_class(trainY, devY):\n",
    "    # Use Counter to count the occurrences of each label in the training data\n",
    "    label_counts = Counter(trainY)\n",
    "    # Find the most common label and its count, then extract just the label\n",
    "    majority_label = label_counts.most_common(1)[0][0]\n",
    "    \n",
    "    # Create a list of predictions by repeating the majority label for every item in the dev set\n",
    "    predictions = [majority_label] * len(devY)\n",
    "    \n",
    "    # Calculate accuracy by comparing predictions to the true dev labels\n",
    "    # This sums up all instances where the prediction matches the true label (evaluates to 1)\n",
    "    correct = sum(p == y for p, y in zip(predictions, devY))\n",
    "    # Accuracy is the number of correct predictions divided by the total number of predictions\n",
    "    accuracy = correct / len(devY)\n",
    "    \n",
    "    # Return the list of predictions and the calculated accuracy\n",
    "    return predictions, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's execute the `majority_class` function to see what our baseline accuracy is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the majority class baseline predictions (p) and accuracy (a)\n",
    "p, a = majority_class(trainY,devY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hyperparameter Tuning (Grid Search)\n",
    "\n",
    "While Scikit-learn's `GridSearchCV` is a powerful tool, building our own grid search gives us more control and helps in understanding the process. We'll explore how different parameter settings for `CountVectorizer` and `LogisticRegression` affect accuracy.\n",
    "\n",
    "First, we'll test a single hyperparameter: `max_features` from `CountVectorizer`, which limits the vocabulary size to the most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store the accuracy scores and parameter names for each trial\n",
    "scores=[]\n",
    "names=[]\n",
    "\n",
    "# Define a list of values for the max_features hyperparameter to test\n",
    "feat_vals=[50, 100, 500, 1000, 5000, 10000, 50000]\n",
    "\n",
    "# Initialize LabelEncoder to convert string labels (e.g., 'positive', 'negative') into integers (e.g., 1, 0)\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Fit the encoder on the training labels to learn the mapping\n",
    "le.fit(trainY)\n",
    "# Transform the training and dev labels into their integer representations\n",
    "Y_train=le.transform(trainY)\n",
    "Y_dev=le.transform(devY)\n",
    "\n",
    "# Initialize a counter for tracking the number of trials\n",
    "idx=0\n",
    "\n",
    "# Loop through each value in our list of feature values\n",
    "for feat_val in feat_vals:\n",
    "\n",
    "    # Initialize CountVectorizer.\n",
    "    # max_features: use the top 'feat_val' most frequent words.\n",
    "    # analyzer=str.split: split text on whitespace (assumes pre-tokenized text).\n",
    "    # lowercase=False: do not convert text to lowercase.\n",
    "    # strip_accents=None: do not remove accents.\n",
    "    # binary=True: use 1s and 0s for word presence, not word counts.\n",
    "    vectorizer = CountVectorizer(max_features=feat_val, analyzer=str.split, lowercase=False, strip_accents=None, binary=True)\n",
    "\n",
    "    # Fit the vectorizer on the training text and transform it into a feature matrix\n",
    "    X_train = vectorizer.fit_transform(trainX)\n",
    "    # Transform the dev text using the same fitted vectorizer\n",
    "    X_dev = vectorizer.transform(devX)\n",
    "\n",
    "    # Print the progress of the grid search\n",
    "    print (\"%s of %s trials\" % (idx, len(feat_vals)))\n",
    "\n",
    "    # Initialize a Logistic Regression model with default parameters\n",
    "    # C=1.0: inverse of regularization strength.\n",
    "    # solver='lbfgs': algorithm to use in the optimization problem.\n",
    "    # penalty='l2': use L2 regularization.\n",
    "    logreg = linear_model.LogisticRegression(C=1.0, solver='lbfgs', penalty='l2')\n",
    "    # Train the model on the vectorized training data and encoded labels\n",
    "    logreg.fit(X_train, Y_train)\n",
    "    # Calculate the accuracy on the dev set and append it to our scores list\n",
    "    scores.append(logreg.score(X_dev, Y_dev))\n",
    "    # Create a descriptive name for this trial and append it to our names list\n",
    "    names.append(\"feat_value:%s\" % (feat_val))\n",
    "    # Increment the trial counter\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use `pandas` to create a DataFrame from our results and plot them in a bar chart to easily compare the performance for different numbers of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame to store and display the results neatly\n",
    "pd_results=pd.DataFrame({\"value\":names, \"accuracy\":scores})\n",
    "# Plot the results as a bar chart to visualize the relationship between the number of features and accuracy\n",
    "pd_results.plot.bar(x='value', y='accuracy', figsize=(14,6))\n",
    "# Display the DataFrame\n",
    "pd_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tuning Multiple Hyperparameters\n",
    "\n",
    "Some parameters interact with each other. For example, the optimal number of features might depend on the regularization strength of the model. Here, we'll perform a grid search on two interacting hyperparameters:\n",
    "1.  **`max_features`** from `CountVectorizer`.\n",
    "2.  **`C`** (regularization strength) from `LogisticRegression`. A smaller `C` value means stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize empty lists to store the new results\n",
    "scores=[]\n",
    "names=[]\n",
    "\n",
    "# Define the list of values for max_features to test\n",
    "feat_vals=[50, 100, 500, 1000, 5000, 10000, 50000]\n",
    "# Define the list of values for the regularization parameter C to test\n",
    "C_values=[0.001, 0.1, 1, 5, 10]\n",
    "\n",
    "# The LabelEncoder is already fitted, so we can reuse the encoded labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(trainY)\n",
    "Y_train=le.transform(trainY)\n",
    "Y_dev=le.transform(devY)\n",
    "\n",
    "# Initialize a trial counter\n",
    "idx=0\n",
    "\n",
    "# Outer loop: iterate through each max_features value\n",
    "for feat_val in feat_vals:\n",
    "\n",
    "    # Create the feature matrix for the current feat_val\n",
    "    vectorizer = CountVectorizer(max_features=feat_val, analyzer=str.split, lowercase=False, strip_accents=None, binary=True)\n",
    "    X_train = vectorizer.fit_transform(trainX)\n",
    "    X_dev = vectorizer.transform(devX)\n",
    "\n",
    "    # Inner loop: iterate through each C value for the current feature set\n",
    "    for C_val in C_values:\n",
    "        \n",
    "        # Print the progress of the grid search\n",
    "        print (\"%s of %s trials\" % (idx, len(feat_vals)*len(C_values)))\n",
    "\n",
    "        # Initialize the Logistic Regression model with the current C_val\n",
    "        logreg = linear_model.LogisticRegression(C=C_val, solver='lbfgs', penalty='l2')\n",
    "        # Train the model\n",
    "        logreg.fit(X_train, Y_train)\n",
    "        # Score the model and append the accuracy to the scores list\n",
    "        scores.append(logreg.score(X_dev, Y_dev))\n",
    "        # Create a descriptive name including both hyperparameter values and append it\n",
    "        names.append(\"feat_value:%s-C:%s\" % (feat_val, C_val))\n",
    "        # Increment the trial counter\n",
    "        idx+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's visualize the results from the two-parameter grid search to find the best combination of `max_features` and `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the results of the two-parameter grid search\n",
    "pd_results=pd.DataFrame({\"value\":names, \"accuracy\":scores})\n",
    "# Plot the results as a bar chart. This will help identify the best-performing combination.\n",
    "pd_results.plot.bar(x='value', y='accuracy', figsize=(14,6))\n",
    "# Display the results DataFrame\n",
    "pd_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loc",
   "language": "python",
   "name": "loc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
