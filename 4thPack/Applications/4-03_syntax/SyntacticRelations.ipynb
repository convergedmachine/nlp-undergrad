{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores dependency parsing by identifying the actions and objects that are characteristically associated with male and female characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1: Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spacy library for Natural Language Processing.\n",
    "import spacy, math\n",
    "# Import the Counter class from the collections module for counting hashable objects.\n",
    "from collections import Counter\n",
    "# Import the operator module to use its functions for sorting.\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2: Loading the SpaCy Model\n",
    "\n",
    "This next cell loads SpaCy's pre-trained English language model. This model contains the statistical information needed to process text, including tokenization, part-of-speech tagging, and dependency parsing. The variable `nlp` will now be a function that can process any English text we provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the default English language model from spacy.\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "\"\"\"\n",
    "This is a commented-out workaround. If loading 'en' fails,\n",
    "this line loads a specific, smaller English model as an alternative.\n",
    "\"\"\"\n",
    "# nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 3: Defining and Processing Text Files\n",
    "\n",
    "We'll run seven novels by Jane Austen through spaCy (this will take a few minutes).\n",
    "\n",
    "The code below defines a list of the text files to be analyzed. It then loops through each file, reads its content, and processes the text with our `nlp` object. All the processed tokens from all novels are collected into a single list called `all_tokens` for a comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of file paths for the seven Jane Austen novels.\n",
    "filenames=[\"../data/fiction/emma.txt\", \"../data/fiction/lady_susan.txt\", \"../data/fiction/mansfield_park.txt\", \"../data/fiction/northanger_abbey.txt\", \"../data/fiction/persuasion.txt\", \"../data/fiction/pride.txt\", \"../data/fiction/sense_and_sensibility.txt\"]\n",
    "# Initialize an empty list to store all the tokens from all the novels.\n",
    "all_tokens=[]\n",
    "# Start a loop to iterate through each file path in the 'filenames' list.\n",
    "for filename in filenames:\n",
    "    # Print the name of the file currently being processed.\n",
    "    print(filename)\n",
    "    # Open the file with UTF-8 encoding, read its entire content, and store it in the 'data' variable.\n",
    "    data=open(filename, encoding=\"utf-8\").read()\n",
    "    # Process the text of the novel using the loaded spacy model, creating a Doc object.\n",
    "    tokens=nlp(data)\n",
    "    # Append all the tokens from the current novel to the master list 'all_tokens'.\n",
    "    all_tokens.extend(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 4: Verifying the Corpus Size\n",
    "\n",
    "To get a sense of the scale of our data, we print the total number of tokens processed from all novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the total number of tokens collected from all the novels.\n",
    "print (len(all_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 5: Defining the Statistical Test Function\n",
    "\n",
    "This cell defines a crucial helper function, `test`. Its purpose is to compare two frequency counts (e.g., verbs used by men vs. women) and identify which terms are most characteristic of each group. It uses a statistical measure called the log-odds ratio with an uninformative prior, which is a robust way to find significant differences in word usage between two corpora. The function will print ranked lists of the terms most associated with each of the two input counters.\n",
    "\n",
    "*Note: A bug in the original code where `femaleSum` was incorrectly calculated from `maleCounter.values()` has been corrected in the comments and the final JSON.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes two Counter objects and an optional integer for the number of results to display.\n",
    "def test(maleCounter, femaleCounter, display=25):\n",
    "    \n",
    "    \"\"\" Function that takes two Counter objects as inputs and prints out a ranked list of terms\n",
    "    more characteristic of the first counter than the second.  Here we'll use log-odds\n",
    "    with an uninformative prior (from Monroe et al 2008, \"Fightin Words\", eqn. 22) as our metric.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a dictionary from the maleCounter to start building a combined vocabulary.\n",
    "    vocab=dict(maleCounter) \n",
    "    # Update the vocabulary dictionary with items from the femaleCounter.\n",
    "    vocab.update(dict(femaleCounter))\n",
    "    # Calculate the total count of all items in maleCounter.\n",
    "    maleSum=sum(maleCounter.values())\n",
    "    # Calculate the total count of all items in femaleCounter.\n",
    "    # Original code had a bug here: sum(maleCounter.values()). It is now corrected.\n",
    "    femaleSum=sum(femaleCounter.values())\n",
    "\n",
    "    # Initialize an empty dictionary to store the calculated scores for each word.\n",
    "    ranks={}\n",
    "    # Set a smoothing parameter (prior) to avoid division-by-zero errors.\n",
    "    alpha=0.01\n",
    "    # Calculate the total prior count across the entire vocabulary.\n",
    "    alphaV=len(vocab)*alpha\n",
    "        \n",
    "    # Loop through every unique word found in either counter.\n",
    "    for word in vocab:\n",
    "        \n",
    "        # Calculate the log-odds ratio, a measure of how much more likely a word is in the \"male\" context vs. the \"female\" context.\n",
    "        log_odds_ratio=math.log( (maleCounter[word] + alpha) / (maleSum+alphaV-maleCounter[word]-alpha) ) - math.log( (femaleCounter[word] + alpha) / (femaleSum+alphaV-femaleCounter[word]-alpha) )\n",
    "        # Calculate the variance of the log-odds ratio.\n",
    "        variance=1./(maleCounter[word] + alpha) + 1./(femaleCounter[word] + alpha)\n",
    "        \n",
    "        # Calculate the z-score (standardized log-odds) and store it. This normalizes the score, making it more robust.\n",
    "        ranks[word]=log_odds_ratio/math.sqrt(variance)\n",
    "\n",
    "    # Sort the ranks dictionary by its values (the z-scores) in descending order.\n",
    "    sorted_x = sorted(ranks.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    # Print a header for the male-associated terms.\n",
    "    print(\"Most male:\")\n",
    "    # Loop through the top 'display' items (most characteristic of males).\n",
    "    for k,v in sorted_x[:display]:\n",
    "        # Print the score (formatted to 3 decimal places) and the word.\n",
    "        print(\"%.3f\\t%s\" % (v,k))\n",
    "    \n",
    "    # Print a header for the female-associated terms.\n",
    "    print(\"\\nMost female:\")\n",
    "    # Loop through the bottom 'display' items (most characteristic of females) in reverse to show them from most to least female-associated.\n",
    "    for k,v in reversed(sorted_x[-display:]):\n",
    "        # Print the score and the word.\n",
    "        print(\"%.3f\\t%s\" % (v,k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 6: Understanding Dependency Parsing\n",
    "\n",
    "SpaCy uses the [ClearNLP dependency labels](https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md), which are very close to the Stanford typed dependencies. See the [Stanford dependencies manual](https://nlp.stanford.edu/software/dependencies_manual.pdf) for more information about each tag. Parse information is contained in the spacy token object; see the following for which attributes encode the token text, `idx` (position in sentence), part of speech, and dependency relation. The syntactic head for a token is another token given in `token.head` (where all of those same token attributes are accessible)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 7: Dependency Parsing Example\n",
    "\n",
    "To illustrate how dependency parsing works in spaCy, we process a sample sentence: \"He started his car.\". The code below iterates through each token and prints its text, its dependency label (`dep_`), and the text of its syntactic 'head' (the word it modifies or is governed by). This demonstrates how we can navigate the syntactic tree of a sentence to find relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a simple sentence with the spacy nlp object.\n",
    "testDoc=nlp(\"He started his car.\")\n",
    "# Iterate through each token in the processed sentence.\n",
    "for token in testDoc:\n",
    "    # Print several attributes for each token to show the dependency parse information.\n",
    "    # token.text: The word itself.\n",
    "    # token.idx: The character index where the token begins.\n",
    "    # token.tag_: The fine-grained part-of-speech tag.\n",
    "    # token.dep_: The syntactic dependency label.\n",
    "    # token.head.text: The text of the syntactic head (the word it's attached to).\n",
    "    # token.head.idx: The starting character index of the head token.\n",
    "    # token.head.tag_: The fine-grained POS tag of the head token.\n",
    "    print(\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\" % (token.text, token.idx, token.tag_, token.dep_, token.head.text, token.head.idx, token.head.tag_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 8: Question 1 - Male vs. Female Subjects\n",
    "\n",
    "**Q1:** Find the verbs that men are more characteristically the *subject* of than women. Feel free to only consider subjects that are \"he\" and \"she\" pronouns. This function should return two `Counter` objects (`maleCounter` and `femaleCounter`) which count the number of times a given verb has \"he\" (`maleCounter`) and \"she\" (`femaleCounter`) as its syntactic subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 9: Implementation for Q1\n",
    "\n",
    "Here, we implement the `count_subjects` function. It iterates through all tokens in our corpus. For each token, it checks if it is a nominal subject (`nsubj`). If it is, and the token is 'he' or 'she', it increments the count for the verb's base form (lemma) in the corresponding male or female counter. The verb is identified as the syntactic `head` of the subject token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to count verbs for male and female subjects.\n",
    "def count_subjects():\n",
    "    # Initialize a counter for verbs with \"he\" as the subject.\n",
    "    maleCounter=Counter()\n",
    "    # Initialize a counter for verbs with \"she\" as the subject.\n",
    "    femaleCounter=Counter()\n",
    "\n",
    "    # Loop through every single token in the Jane Austen corpus.\n",
    "    for token in all_tokens:\n",
    "        # Check if the token's dependency label is 'nsubj' (nominal subject).\n",
    "        if token.dep_ == \"nsubj\":\n",
    "            # If the subject's text (lowercased) is \"he\"...\n",
    "            if token.text.lower() == \"he\":\n",
    "                # ...find its syntactic head (the verb) and increment the count for that verb's base form (lemma).\n",
    "                maleCounter[token.head.lemma_]+=1\n",
    "            # Else if the subject's text (lowercased) is \"she\"...\n",
    "            elif token.text.lower() == \"she\":\n",
    "                # ...increment the count for that verb's base form in the female counter.\n",
    "                femaleCounter[token.head.lemma_]+=1\n",
    "    \n",
    "    # Return the two populated counters.\n",
    "    return maleCounter, femaleCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 10: Running the Analysis for Q1\n",
    "\n",
    "Now we execute our `count_subjects` function and pass the resulting counters to our `test` function. This will analyze the frequencies and print the verbs that are most characteristically associated with male subjects ('he') and female subjects ('she') in Austen's novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to get the subject-verb counts and store them in 'male' and 'female' variables.\n",
    "male, female=count_subjects()\n",
    "# Use the 'test' function to analyze these counts and print the 10 most characteristic verbs for each gender.\n",
    "test(male, female, display=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 11: Question 2 - Male vs. Female Objects\n",
    "\n",
    "**Q2:** Find the verbs that men are more characteristically the *object* of than women. Feel free to only consider objects that are \"him\" and \"her\" pronouns. This function should return two `Counter` objects (`maleCounter` and `femaleCounter`) which count the number of times a given verb has \"him\" (`maleCounter`) and \"her\" (`femaleCounter`) as its syntactic direct object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 12: Implementation for Q2\n",
    "\n",
    "For Q2, we create the `count_objects` function. This is very similar to the previous function, but instead of looking for subjects (`nsubj`), it looks for direct objects (`dobj`). When it finds a 'him' or 'her' token that is a direct object, it increments the count for the verb (the token's `head`) in the appropriate counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to count verbs for male and female objects.\n",
    "def count_objects():\n",
    "    # Initialize a counter for verbs with \"him\" as the object.\n",
    "    maleCounter=Counter()\n",
    "    # Initialize a counter for verbs with \"her\" as the object.\n",
    "    femaleCounter=Counter()\n",
    "\n",
    "    # Loop through all tokens in the corpus.\n",
    "    for token in all_tokens:\n",
    "        # Check if the token's dependency label is 'dobj' (direct object).\n",
    "        if token.dep_ == \"dobj\":\n",
    "            # If the object's text (lowercased) is \"him\"...\n",
    "            if token.text.lower() == \"him\":\n",
    "                # ...find its head (the verb) and increment its lemma in the male counter.\n",
    "                maleCounter[token.head.lemma_]+=1\n",
    "            # Else if the object's text (lowercased) is \"her\"...\n",
    "            elif token.text.lower() == \"her\":\n",
    "                # ...increment its lemma in the female counter.\n",
    "                femaleCounter[token.head.lemma_]+=1\n",
    "    \n",
    "    # Return the populated counters.\n",
    "    return maleCounter, femaleCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 13: Running the Analysis for Q2\n",
    "\n",
    "We run the `count_objects` function and feed its output into the `test` function to see which verbs are most characteristically used with male and female direct objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to get the verb-object counts.\n",
    "male, female=count_objects()\n",
    "# Analyze and print the 10 most characteristic verbs for male and female objects.\n",
    "test(male, female, display=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 14: Question 3 - Male vs. Female Possessions\n",
    "\n",
    "**Q3:** Find the objects that are *possessed* more frequently by men than women. Feel free to only consider possessors that are \"his\" and \"her\" pronouns. This function should return two `Counter` objects (`maleCounter` and `femaleCounter`) which counts the number of times a given term is possessed by \"his\" (`maleCounter`) and \"her\" (`femaleCounter`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 15: Implementation for Q3\n",
    "\n",
    "To answer Q3, we write the `count_possessions` function. It searches for tokens with the dependency label `poss` (possessive determiner). If the token is 'his' or 'her', it identifies the noun being possessed (the `head` of the possessive token) and adds its base form (lemma) to the respective counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to count possessions for males and females.\n",
    "def count_possessions():\n",
    "    # Initialize a counter for nouns possessed by \"his\".\n",
    "    maleCounter=Counter()\n",
    "    # Initialize a counter for nouns possessed by \"her\".\n",
    "    femaleCounter=Counter()\n",
    "\n",
    "    # Loop through all tokens in the corpus.\n",
    "    for token in all_tokens:\n",
    "        # Check if the token's dependency label is 'poss' (possessive).\n",
    "        if token.dep_ == \"poss\":\n",
    "            # If the possessive pronoun is \"his\"...\n",
    "            if token.text.lower() == \"his\":\n",
    "                # ...find its head (the noun being possessed) and increment its lemma in the male counter.\n",
    "                maleCounter[token.head.lemma_]+=1\n",
    "            # Else if the possessive pronoun is \"her\"...\n",
    "            elif token.text.lower() == \"her\":\n",
    "                # ...increment the possessed noun's lemma in the female counter.\n",
    "                femaleCounter[token.head.lemma_]+=1\n",
    "    \n",
    "    # Return the populated counters.\n",
    "    return maleCounter, femaleCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 16: Running the Analysis for Q3\n",
    "\n",
    "Executing `count_possessions` and `test` reveals the nouns that are most distinctively possessed by men ('his') and women ('her') in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to get the possession counts.\n",
    "male, female=count_possessions()\n",
    "# Analyze and print the 10 most characteristic possessed nouns for each gender.\n",
    "test(male, female, display=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 17: Question 4 - Subject-Verb-Object Tuples\n",
    "\n",
    "**Q4:** Find the actions that men do *to women* more frequently than women do *to men*. Feel free to only consider subjects and objects that are \"she\"/\"he\"/\"her\"/\"him\" pronouns. This function should return two `Counter` objects (`maleCounter` and `femaleCounter`) which count the number of times a given verb has \"he\" as the subject and \"her\" as the object (`maleCounter`) and \"she\" as the subject and \"him\" as the object (`femaleCounter`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 18: Implementation for Q4\n",
    "\n",
    "This final question is the most complex. The `count_SVO_tuples` function tackles this in two stages. First, it iterates through all tokens to create two dictionaries: one mapping verbs to their 'he'/'she' subjects, and another mapping verbs to their 'him'/'her' objects. Then, it iterates through the verbs that appear in *both* dictionaries, checks the subject-object pairings for that specific verb instance, and increments the appropriate counter (`maleCounter` for 'he-verb-her', `femaleCounter` for 'she-verb-him')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to count specific Subject-Verb-Object patterns.\n",
    "def count_SVO_tuples():\n",
    "    # Initialize a counter for 'he-verb-her' patterns.\n",
    "    maleCounter=Counter()\n",
    "    # Initialize a counter for 'she-verb-him' patterns.\n",
    "    femaleCounter=Counter()\n",
    "\n",
    "    # Initialize dictionaries to store verbs and their associated objects or subjects.\n",
    "    dobj_verbs={}\n",
    "    nsubj_verbs={}\n",
    "\n",
    "    # First pass: iterate through all tokens to collect subjects and objects for each verb instance.\n",
    "    for token in all_tokens:\n",
    "        # Check if the token is a direct object.\n",
    "        if token.dep_ == \"dobj\":\n",
    "            # Filter for \"him\" or \"her\".\n",
    "            if token.text.lower() == \"him\" or token.text.lower() == \"her\":\n",
    "                # Get the verb (the head of the object).\n",
    "                head=token.head\n",
    "                # If this is the first time we see this verb instance, initialize a list for it.\n",
    "                if head not in dobj_verbs:\n",
    "                    dobj_verbs[head]=[]\n",
    "                # Append the object token ('him' or 'her') to the list for that verb.\n",
    "                dobj_verbs[head].append(token)\n",
    "                \n",
    "        # Check if the token is a nominal subject.\n",
    "        if token.dep_ == \"nsubj\":\n",
    "            # Filter for \"he\" or \"she\".\n",
    "            if token.text.lower() == \"he\" or token.text.lower() == \"she\":\n",
    "                # Get the verb (the head of the subject).\n",
    "                head=token.head\n",
    "                # If this is the first time we see this verb instance, initialize a list for it.\n",
    "                if head not in nsubj_verbs:\n",
    "                    nsubj_verbs[head]=[]\n",
    "                # Append the subject token ('he' or 'she') to the list for that verb.\n",
    "                nsubj_verbs[head].append(token)\n",
    "\n",
    "    # Second pass: iterate through verbs that had objects to find matching subjects.\n",
    "    for head_verb in dobj_verbs:\n",
    "        # Check if the same verb instance also had a subject we recorded.\n",
    "        if head_verb in nsubj_verbs:\n",
    "            \n",
    "            # Loop through all subjects found for this verb instance.\n",
    "            for subjectToken in nsubj_verbs[head_verb]:\n",
    "                # Loop through all objects found for this verb instance.\n",
    "                for objectToken in dobj_verbs[head_verb]:\n",
    "                    # Check for the \"he -> verb -> her\" pattern.\n",
    "                    if subjectToken.text.lower() == \"he\" and objectToken.text.lower() == \"her\":\n",
    "                        # If found, increment the verb's lemma in maleCounter.\n",
    "                        maleCounter[head_verb.lemma_]+=1\n",
    "                    # Check for the \"she -> verb -> him\" pattern.\n",
    "                    elif subjectToken.text.lower() == \"she\" and objectToken.text.lower() == \"him\":\n",
    "                        # If found, increment the verb's lemma in femaleCounter.\n",
    "                        femaleCounter[head_verb.lemma_]+=1\n",
    "\n",
    "    # Return the final counts.                \n",
    "    return maleCounter, femaleCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 19: Running the Analysis for Q4\n",
    "\n",
    "Finally, we call `count_SVO_tuples` and `test` to see the results. This reveals the actions men are more likely to perform on women and the actions women are more likely to perform on men, according to the pronouns used in Jane Austen's novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to get the SVO pattern counts.\n",
    "male, female=count_SVO_tuples()\n",
    "# Analyze and print the 10 most characteristic verbs for each pattern.\n",
    "test(male, female, display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loc",
   "language": "python",
   "name": "loc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
